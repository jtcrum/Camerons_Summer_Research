{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "259fcc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from zse.collections import *\n",
    "from zse.utilities import *\n",
    "\n",
    "from ase.io import read, write\n",
    "from matplotlib import cm\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score, completeness_score, homogeneity_score, mean_squared_error\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import itertools\n",
    "from itertools import permutations\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sys\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from kneed import KneeLocator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af509027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fw_data(file,code):\n",
    "    \n",
    "    # file is the file we want to read from\n",
    "    # code is the IZA framework code you want data on\n",
    "    \n",
    "    file = open(file,'r')\n",
    "    data = file.readlines()\n",
    "    file.close()\n",
    "    \n",
    "    for i,line in enumerate(data):\n",
    "        fields = line.split()\n",
    "        if fields[0] == code:\n",
    "            start = i\n",
    "            break\n",
    "    \n",
    "    # go through fw chunk and get data\n",
    "    \n",
    "    t_sites = {}\n",
    "    o_sites = {}\n",
    "    for i,line in enumerate(data[start+1:]):\n",
    "        line = line.rstrip(' \\n')\n",
    "\n",
    "        # get the t site rings\n",
    "        \n",
    "        if 'T' in line and ':' in line:\n",
    "            fields = line.split(':')\n",
    "            t_sites[fields[0]]=fields[1]                \n",
    "        \n",
    "        # get the o site rings\n",
    "        \n",
    "        if 'O' in line and ':' in line:\n",
    "            fields = line.split(':')\n",
    "            o_sites[fields[0]]=fields[1]        \n",
    "        \n",
    "        fields = line.split()\n",
    "        if fields[0] == 'Framework':\n",
    "            end = i+start-1\n",
    "            break\n",
    "\n",
    "    return(t_sites,o_sites)    \n",
    "\n",
    "def numofrings(file,code):\n",
    "    #might already be a function called counter so come up with very unique names otherwsie function overrides it -- isseue with kernel resets\n",
    "    '''takes in the file and code name and returns how many of each ring type is present\n",
    "    arguments: file: dataset\n",
    "                code: which zeolite is being observed\n",
    "    returns: number of each rings inside'''\n",
    "    \n",
    "    #call function to get data\n",
    "    tsites, osites = get_fw_data(file,code)\n",
    "    \n",
    "    for t in tsites:\n",
    "        #print('check 1')\n",
    "        #resets dictionary each tsite\n",
    "        tsite_dict = {1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0,10:0,11:0,12:0}\n",
    "        #ways to make dictionary without knowing what it is \n",
    "        \n",
    "        #make into vector not dictionary \n",
    "        \n",
    "        #restarts j to 1 to check for ring size\n",
    "        j = 1\n",
    "        #go through all of the one tsite\n",
    "        for i in range(0,len(tsites[t])-2,2):\n",
    "            #print('check 2')\n",
    "            #set yes to true\n",
    "            print('i is',i)\n",
    "            yes = True\n",
    "            while yes:\n",
    "                #print('check 3')\n",
    "                #print(tsites[t][i])\n",
    "                #print(int(tsites[t][i]) == j)\n",
    "                #print(tsite_dict[j])\n",
    "                #number of rings matches dictionary component\n",
    "                if int(tsites[t][i]) == j:\n",
    "                    print('check 4')\n",
    "                    tsite_dict[j] = tsite_dict[j] + 1\n",
    "                    #end while loop \n",
    "                    yes = False\n",
    "                #increase j \n",
    "                else:\n",
    "                    \n",
    "                    j = j + 1\n",
    "                    print('j is',j)\n",
    "        print(t,tsite_dict)\n",
    "        \n",
    "\n",
    "def nringsvector(code,file):\n",
    "    '''takes in the file and code name and returns how many of each ring type is present\n",
    "    arguments: file: dataset\n",
    "                code: which zeolite is being observed\n",
    "    returns: vector of number of rings for each tsite'''\n",
    "    \n",
    "    #get site data\n",
    "    tsites, osites = get_fw_data(file,code)\n",
    "    \n",
    "    #create empty vector\n",
    "    A = np.zeros([len(tsites),21])\n",
    "    \n",
    "    #coutner for which row of the matrix you are in\n",
    "    k=0 \n",
    "    \n",
    "    #go through each tsite\n",
    "    for t in tsites:\n",
    "        #initialize accumulator \n",
    "        j=1\n",
    "        \n",
    "        #make list of number of rings\n",
    "        tsites_list = tsites[t].split('_')\n",
    "        #go through the string for each t list\n",
    "        for i in range(0,len(tsites_list)):\n",
    "            #make the while loop true each for loop\n",
    "            yes = True\n",
    "            while yes:\n",
    "                if int(tsites_list[i]) == j:\n",
    "                    A[k][j] = A[k][j] + 1\n",
    "                    #end while loop \n",
    "                    yes = False\n",
    "                #increase j \n",
    "                else:\n",
    "                    j = j + 1\n",
    "        #increase row\n",
    "        k = k +1 \n",
    "    return A\n",
    "\n",
    "def assemblematrix(file):\n",
    "    fws = get_all_fws()\n",
    "    fws = fws[1:]\n",
    "    B = nringsvector('ABW',file)\n",
    "    for code in fws:\n",
    "        C = nringsvector(code,file)\n",
    "        B = np.append(B, C, axis=0)\n",
    "    return B\n",
    "\n",
    "def kmeans_percent(file,ncluster):\n",
    "    A = assemblematrix(file)\n",
    "    clustering = KMeans(n_clusters = ncluster).fit(A)\n",
    "    cluster = clustering.labels_\n",
    "\n",
    "    sorted_clusters = defaultdict(list) #inside parentheses put the type of value ie list int\n",
    "\n",
    "    fws = get_all_fws()\n",
    "    #testing to see if Tsite make it a similar cluster\n",
    "    dict_fws = {}\n",
    "    count = 0\n",
    "    for code in fws:\n",
    "        dict_fws[code] = []\n",
    "        tsites, osites = get_fw_data(file,code)\n",
    "        for t in tsites:\n",
    "            dict_fws[code].append(cluster[count])\n",
    "            count = count + 1\n",
    "    allsame = 0\n",
    "    no1 = 0\n",
    "    for k in dict_fws:\n",
    "        if len(dict_fws[k]) > 1:\n",
    "            no1 = no1 + 1\n",
    "            avg = sum(dict_fws[k])/len(dict_fws[k])\n",
    "            if avg == dict_fws[k][0]:\n",
    "                if dict_fws[k][0] == dict_fws[k][len(dict_fws[k])-1]:\n",
    "                    allsame = allsame + 1\n",
    "    per = allsame/no1\n",
    "    return per, dict_fws \n",
    "\n",
    "def weight_avg(file):\n",
    "    '''Takes in a files frameworks and makes a wieghted average for each framewokr\n",
    "        Arguments: file - whichever defintion of ring used\n",
    "        returns: an array of the values'''\n",
    "    fws = get_all_fws()\n",
    "    fws_weights = np.zeros([len(fws),21])\n",
    "    count = 0\n",
    "    for code in fws:\n",
    "        #get tsite sata\n",
    "        tsites, osites = get_fw_data(file,code)\n",
    "        ts, tm, ti = get_tsites(code)\n",
    "        #number of tsites\n",
    "        n = len(tsites)\n",
    "        #get the matrix of the tsite vectors\n",
    "        rings = nringsvector(code,file)\n",
    "        temp = np.zeros(len(rings[0]))\n",
    "        #to move through the rings matrix\n",
    "        ring_count = 0\n",
    "        #calculate weights and add them rows of tsite values together\n",
    "        for s,m,i in zip(ts,tm,ti):\n",
    "            #calculate weight\n",
    "            w = m/sum(tm)\n",
    "            #make weighted framework\n",
    "            temp = w*rings[ring_count] + temp\n",
    "            ring_count = ring_count + 1\n",
    "        fws_weights[count] = temp\n",
    "        #increase row number\n",
    "        count = count + 1\n",
    "    return fws_weights\n",
    "\n",
    "def compare4(A,B,nclusters,rand_state,vbool=False):\n",
    "    #get data \n",
    "    Azlist, Aist = Kmeansresults(A,nclusters,rand_state,False)\n",
    "    Bzlist, Bist = Kmeansresults(B,nclusters,rand_state,False)\n",
    "\n",
    "    #print(Aist)\n",
    "    #print(Bist)\n",
    "    #make default dictionaries to reorganzie the zlist\n",
    "    Alist = defaultdict(list)\n",
    "    Blist = defaultdict(list)\n",
    "    \n",
    "    #sort the dictionaries numerically\n",
    "    m = 0\n",
    "    for k in (sorted(Azlist, key=lambda k: len(Azlist[k]), reverse=True)):\n",
    "        Alist[m] = Azlist[k]\n",
    "        m = m + 1\n",
    "    m = 0\n",
    "    for k in sorted(Bzlist, key=lambda k: len(Bzlist[k]), reverse=True):\n",
    "        Blist[m] = Bzlist[k]\n",
    "        m = m + 1   \n",
    "    # combinations\n",
    "    unique_combinations = []\n",
    " \n",
    "    # Getting all permutations of list_1\n",
    "    # with length of list_2\n",
    "    permut = itertools.permutations(Alist, len(Blist))\n",
    "    # zip() is called to pair each permutation\n",
    "    # and shorter list element into combination\n",
    "    for comb in permut:\n",
    "        zipped = zip(comb, Blist)\n",
    "        unique_combinations.append(list(zipped))\n",
    "       \n",
    "    \n",
    "    #create an array to store values\n",
    "    array_values = np.zeros([nclusters,nclusters])\n",
    "    #print('')\n",
    "    #loop over unique combinations \n",
    "    for n in range(nclusters):\n",
    "        for i in range(nclusters):\n",
    "            #index into the first part of the ordered pair\n",
    "            a = unique_combinations[n][i][0]\n",
    "            #index into the second part of the ordered pair\n",
    "            b = unique_combinations[n][i][1]\n",
    "            #find what is in common with the two lists \n",
    "            c = list(set(Alist[a]).intersection(Blist[b]))\n",
    "            #add the value to the array\n",
    "            array_values[n,i] = len(c)\n",
    "    #print(array_values)\n",
    "    #print('')\n",
    "    \n",
    "    #store results \n",
    "    temp = []\n",
    "    #print results \n",
    "    for t in range(nclusters):\n",
    "        #print(sum(array_values[t])/253)\n",
    "        temp.append(sum(array_values[t])/253)\n",
    "        \n",
    "    return temp\n",
    "\n",
    "def isNaN(num):\n",
    "    return num!= num\n",
    "\n",
    "def properties(A,values,nclusters,vbool=False):\n",
    "    '''Arguments:\n",
    "    \n",
    "        A: the assembled matrix\n",
    "        nclusters: number of clusters\n",
    "        values: data framework to be texted'''\n",
    "    #get all the frameworks\n",
    "    fws = get_all_fws()\n",
    "    #get the clusters\n",
    "    Azlist, Aist = Kmeansresults(A,nclusters,vbool)\n",
    "    print(Aist)\n",
    "    #create a values dictionary to store the frameworks IZa values\n",
    "    value_dict = defaultdict(list)\n",
    "    #go through all the clusters\n",
    "    for k in Azlist:\n",
    "        #go through all the frameworks in each cluster\n",
    "        for i in range(len(Azlist[k])):\n",
    "            #find the index for the framework\n",
    "            idx = fws.index(Azlist[k][i])\n",
    "            if isNaN(values[idx]) != True:\n",
    "                #add the framework's values to the dictionary\n",
    "                value_dict[k].append(int(values[idx]))\n",
    "    \n",
    "    \n",
    "    #list of the averages\n",
    "    avg = []\n",
    "    #list of the standard deviations\n",
    "    stdev = []\n",
    "    for k in value_dict:\n",
    "        x = sum(value_dict[k])/len(value_dict[k])\n",
    "        avg.append(x)\n",
    "        y = np.std(value_dict[k])\n",
    "        stdev.append(y)\n",
    "                   \n",
    "    return avg, stdev\n",
    "\n",
    "def Kmeansresults(A,n,minusBSV = False):\n",
    "    \n",
    "    fws = get_all_fws()\n",
    "    if minusBSV == True:\n",
    "        fws = np.concatenate((fws[0:39],fws[40:]))\n",
    "    clustering = KMeans(n,random_state=9).fit(A)\n",
    "    cluster = clustering.labels_\n",
    "\n",
    "    zlist = defaultdict(list)\n",
    "    for i in range(len(cluster)):\n",
    "        zlist[cluster[i]].append(fws[i])\n",
    "    llist = []\n",
    "    for i in range(n):\n",
    "        llist.append(len(zlist[i]))\n",
    "    #llist.sort()\n",
    "    \n",
    "    return zlist, llist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b095b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = weight_avg('../Data/vertex_rings.txt')\n",
    "B = weight_avg('../Data/sastre_rings.txt')\n",
    "C = weight_avg('../Data/crum_rings.txt')\n",
    "D = weight_avg('../Data/goetzke_rings.txt')\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "# transform data\n",
    "scaledA = scaler.fit_transform(A)\n",
    "scaledB = scaler.fit_transform(B)\n",
    "scaledC = scaler.fit_transform(C)\n",
    "scaledD = scaler.fit_transform(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6724a293",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \n",
    "for n in range(2,500,)\n",
    "for i in range(2,60):\n",
    "    clustering = KMeans(i,rand_state = ).fit(scaledA)\n",
    "    cluster = clustering.labels_\n",
    "    silhouette_score(C,cluster))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
